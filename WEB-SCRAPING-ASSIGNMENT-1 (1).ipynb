{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf2f425",
   "metadata": {},
   "source": [
    "# Question_1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2629aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee098fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "content=BeautifulSoup(page.content)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Header = []\n",
    "for header in content.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    Header.append(header.name+\" \"+header.text.strip( ))\n",
    "Header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff37f96",
   "metadata": {},
   "source": [
    "# 2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9cb6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = []\n",
    "year = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = soup.findAll('div', attrs= {'class': 'lister-item mode-advanced'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15209ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in movie_data:\n",
    "    name = store.h3.a.text\n",
    "name\n",
    "\n",
    "for store in movie_data:\n",
    "    name = store.h3.a.text\n",
    "    movie.append(name)\n",
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fcfce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = soup.findAll('div', attrs= {'class': 'lister-item mode-advanced'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf88304",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_ratings = soup.find_all('div', class_='inline-block ratings-imdb-rating')\n",
    "scraped_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd72bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse Rating\n",
    "ratings = []\n",
    "for rating in scraped_ratings:\n",
    "    rating = rating.get_text().replace('\\n', '')\n",
    "    ratings.append(rating)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d656f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping year\n",
    "for i in soup.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe\n",
    "data = list(zip(movie,year,ratings))\n",
    "df = pd.DataFrame(data,columns=[\"movie\",\"year\",\"ratings\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5418df",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33707a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbb326",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee12f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "    response=requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Failed to load page {url}')\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ccac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=get_topics_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_movie_titles(soup)\n",
    "titles[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_year(soup):\n",
    "    year_selector = \"secondaryInfo\"           \n",
    "    movie_year_tags=soup.find_all('span',{'class':year_selector})\n",
    "    movie_year_tagss=[]\n",
    "    for tag in movie_year_tags:\n",
    "        movie_year_tagss.append(tag.get_text().strip()[1:100])\n",
    "    return movie_year_tagss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = get_movie_year(soup)\n",
    "years[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc78486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_rating(soup):\n",
    "    rating_selector=\"ratingColumn imdbRating\"         \n",
    "    movie_rating_tags=soup.find_all('td',{'class':rating_selector})\n",
    "    movie_rating_tagss=[]\n",
    "    for tag in movie_rating_tags:\n",
    "        movie_rating_tagss.append(tag.get_text().strip())\n",
    "    return movie_rating_tagss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f4a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = get_movie_rating(soup)\n",
    "ratings[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749cab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe\n",
    "data = list(zip(titles,years,ratings))\n",
    "df = pd.DataFrame(data,columns=[\"titles\",\"years\",\"ratings\"])\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f3c9d",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d64933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbfec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3270f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "President_name = []\n",
    "Tenure = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "president_data = soup.findAll('div', attrs= {'class': 'presidentListing'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b221e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in president_data:\n",
    "    name = store.h3.text\n",
    "    President_name.append(name)\n",
    "President_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in president_data:\n",
    "    time = store.p.text\n",
    "    Tenure.append(time)\n",
    "Tenure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(President_name,Tenure))\n",
    "df = pd.DataFrame(data,columns=[\"President_name\",\"Tenure\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad238a2",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51381534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d908a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team = []\n",
    "match = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813677ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Team\n",
    "for i in soup.find_all('span', class_=\"u-show-phablet\"):\n",
    "    Team.append(i.text)\n",
    "Team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63752dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping match\n",
    "for i in soup.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "    match.append(i.text)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = match[0:18:2]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = match[1:18:2]\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = soup.find('td',class_=\"rankings-block__banner--points\").text\n",
    "point.insert(0,P)\n",
    "point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774032ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = soup.find('td',class_=\"rankings-block__banner--matches\").text\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.insert(0,F)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('td', class_=\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "R=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n', '   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d579172",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.insert(0,R)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84861b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe\n",
    "data = list(zip(Team,matches,point,ratings))\n",
    "df = pd.DataFrame(data,columns=[\"Team\",\"matches\",\"point\",\"ratings\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55138ba5",
   "metadata": {},
   "source": [
    "# 5_b) Top 10 ODI Batsmen along with the records of their team and rating.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a887a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d93113",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63602fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cdc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name= []\n",
    "rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a45e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping batsman\n",
    "scraped_batsman = soup.find_all('td', class_=\"table-body__cell rankings-table__name name\")\n",
    "scraped_batsman\n",
    "\n",
    "batsman = []\n",
    "for B in scraped_batsman:\n",
    "    B = B.get_text().replace('\\n', '')\n",
    "    batsman.append(B)\n",
    "batsman[:9]\n",
    "\n",
    "Name = soup.find('div',class_=\"u-flex-center u-text-left\").text.replace('\\n','')\n",
    "Name\n",
    "batsman.insert(0,Name)\n",
    "batsman[:10]\n",
    "\n",
    "#scraped Team\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    team_name.append(i.text.replace('\\n',''))   \n",
    "    \n",
    "team_name[:10]\n",
    "\n",
    "#Scrape rating\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "r = soup.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "rating.insert(0,r)\n",
    "rating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe559dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe\n",
    "data = list(zip(batsman,team_name,rating))\n",
    "df = pd.DataFrame(data,columns=[\"batsman\",\"team_name\",\"rating\"])\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310d56c",
   "metadata": {},
   "source": [
    "# 5_c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc56780",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba75594",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bowlers = []\n",
    "Team = []\n",
    "Ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Bowlers\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Bowlers.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "B = soup.find('td',class_=\"rankings-block__top-player-container\").text.replace('\\n','')\n",
    "Bowlers.insert(0,B)\n",
    "\n",
    "Bowlers[:10]\n",
    "\n",
    "#  Scraping Team\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Team.append(i.text)\n",
    "T = soup.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n','')\n",
    "T\n",
    "\n",
    "Team.insert(0,T)\n",
    "Team[:10]\n",
    "\n",
    "#Scraping Ratings\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "R = soup.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "R\n",
    "Ratings.insert(0,R)\n",
    "Ratings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe\n",
    "data = list(zip(Bowlers,Team,Ratings))\n",
    "df = pd.DataFrame(data,columns=[\"Bowlers\",\"Team\",\"Ratings\"])\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14258f9b",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313037e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d50ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teams = []\n",
    "Match = []\n",
    "Point = []\n",
    "Ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60a8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Teams\n",
    "for i in soup.find_all('span',class_=\"u-show-phablet\"):\n",
    "    Teams.append(i.text.replace('\\n',' '))\n",
    "Teams[:10]\n",
    "\n",
    "#Scraping Matches\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    Match.append(i.text)\n",
    "Match\n",
    "Matches = Match[0:18:2]\n",
    "Matches\n",
    "\n",
    "M = soup.find('td',class_=\"rankings-block__banner--matches\").text\n",
    "M\n",
    "Matches.insert(0,M)\n",
    "Matches\n",
    "\n",
    "Points = Match[1:18:2]\n",
    "Points\n",
    "P= soup.find('td',class_=\"rankings-block__banner--points\").text\n",
    "P\n",
    "Points.insert(0,P)\n",
    "Points\n",
    "\n",
    "#Scrap Ratings\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    Ratings.append(i.text)\n",
    "Ratings\n",
    "R = soup.find('td',class_=\"rankings-block__banner--rating u-text-right\").text.replace('\\n','')\n",
    "Ratings.insert(0,R)\n",
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49935559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe\n",
    "data = list(zip(Teams,Matches,Points,Ratings))\n",
    "df = pd.DataFrame(data,columns=[\"Teams\",\"Matches\",\"Points\",\"Ratings\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7194313",
   "metadata": {},
   "source": [
    "# 6_ b) Top 10 women’s ODI Batting players along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e52861",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec2bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b03dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Player = []\n",
    "Team = []\n",
    "Rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bdb0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrap Player\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    Player.append(i.text.replace('\\n',''))\n",
    "\n",
    "P = soup.find('td',class_=\"rankings-block__top-player-container\").text.replace('\\n','')\n",
    "Player.insert(0,P)\n",
    "Player[:10]\n",
    "\n",
    "# Scrape Rating\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "R = soup.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "R\n",
    "\n",
    "Rating.insert(0,R)\n",
    "Rating[:10]\n",
    "\n",
    "# Scrape Team\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    Team.append(i.text.replace('\\n',''))\n",
    "    \n",
    "T = soup.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n','')\n",
    "T\n",
    "Team.insert(0,T)\n",
    "Team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e222a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.DataFrame({'PLAYER':Player,'TEAM':Team,'RATING':Rating})\n",
    "DF[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbbf9b9",
   "metadata": {},
   "source": [
    "# 6_c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ade5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e315aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Player = []\n",
    "Team = []\n",
    "Rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Player\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\\\n",
    "    Player.append(i.text.replace('\\n',''))\n",
    "    \n",
    "P = soup.find('td',class_=\"rankings-block__top-player-container\").text.replace('\\n','')\n",
    "P\n",
    "\n",
    "Player.insert(0,P)\n",
    "Player[:10]\n",
    "\n",
    "# scrape Team\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    Team.append(i.text.replace('\\n',''))\n",
    "    \n",
    "T = soup.find('div',class_=\"rankings-block__banner--nationality\").text.replace('\\n','')\n",
    "T\n",
    "\n",
    "Team.insert(0,T)\n",
    "Team[:10]\n",
    "\n",
    "\n",
    "#Scrape Rating\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "R = soup.find('div',class_=\"rankings-block__banner--rating\").text\n",
    "R\n",
    "\n",
    "Rating.insert(0,R)\n",
    "Rating[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2726381",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.DataFrame({'PLAYER':Player,'TEAM':Team,'RATING':Rating})\n",
    "DF[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab78540",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline ii) Time iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL='https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e20c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Headline = []\n",
    "Time = []\n",
    "URL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134291c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraped Headline\n",
    "for i in soup.find_all('div',class_=\"LatestNews-headline\"):\n",
    "    Headline.append(i.text)\n",
    "    \n",
    "Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2bb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraped Team\n",
    "\n",
    "for i in soup.find_all('span',class_=\"LatestNews-wrapper\"):\n",
    "    Time.append(i.text)\n",
    "    \n",
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe86733",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a795ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in URL:\n",
    "    if 'href' in link.attrs:\n",
    "        print(str(link.attrs['href']) + \"\\n\")\n",
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3c532",
   "metadata": {},
   "source": [
    "# 8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details : \n",
    "        i) Paper Title\n",
    "        ii) Authors \n",
    "        iii) Published Date\n",
    "        iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b574e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f75437",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ec6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "Title = []\n",
    "Authors = []\n",
    "Date = []\n",
    "URL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13433a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_data = soup.findAll('li', attrs= {'class': 'sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in articles_data:\n",
    "    name = store.a.text\n",
    "    Title.append(name)\n",
    "    \n",
    "Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9bccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in articles_data:\n",
    "    name = store.span.text\n",
    "    Authors.append(name)\n",
    "    \n",
    "Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca65787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Date\n",
    "for i in soup.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    Date.append(i.text)\n",
    "    \n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in URL:\n",
    "    if 'href' in link.attrs:\n",
    "        print(str(link.attrs['href']) + \"\\n\")\n",
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a2db0",
   "metadata": {},
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name \n",
    "ii) Cuisine \n",
    "iii) Location \n",
    "iv) Ratings \n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de813772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034959cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_name = []\n",
    "cuisines = []\n",
    "restaurant_location = []\n",
    "ratings = []\n",
    "image_URL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_data = soup.findAll('div', attrs= {'class': 'restnt-card restaurant'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ecaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in restaurant_data:\n",
    "    name = store.a.text\n",
    "    restaurant_name.append(name)  \n",
    "    \n",
    "restaurant_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf71462",
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in restaurant_data:\n",
    "    cuisine = store.span.a.text\n",
    "    cuisines.append(cuisine)\n",
    "    \n",
    "cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping location\n",
    "for i in soup.find_all('div', class_=\"restnt-loc ellipsis\"):\n",
    "    restaurant_location.append(i.text)\n",
    "    \n",
    "restaurant_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21509235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping ratings\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd326f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping image_URL\n",
    "image_URL = []\n",
    "a = soup.find_all(\"img\",class_=\"no-img\")\n",
    "for b in a:\n",
    "    #print(str(b['data-src']))\n",
    "    image_URL.append(str(b['data-src']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5989034",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Dataframe\n",
    "data = list(zip(restaurant_name,cuisines,restaurant_location,ratings,image_URL))\n",
    "df = pd.DataFrame(data,columns=[\"restaurant_name\",\"cuisines\",\"restaurant_location\",\"ratings\",\"image_URL\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89932a45",
   "metadata": {},
   "source": [
    "# 10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "https://scholar.google.com/citations?view_op=top_venues&hl=en \n",
    "i) Rank \n",
    "ii) Publication \n",
    "iii) h5-index \n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e6b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e63a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a955733",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "rank = []\n",
    "publication = []\n",
    "h5index = []\n",
    "h5median = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text) \n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping publication \n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "    \n",
    "publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping h5index\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_n\"):\n",
    "    h5index.append(i.text)\n",
    "    \n",
    "h5index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99285649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping \th5median \n",
    "for i in soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5median.append(i.text)\n",
    "    \n",
    "h5median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883dc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Data Frame\n",
    "data = list(zip(rank,publication,h5median,h5index))\n",
    "df = pd.DataFrame(data,columns=[\"rank\",\"publication\",\"h5median\",\"h5index\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaff7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e359b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b8069d2",
   "metadata": {},
   "source": [
    "# Assignment for Web Scraping_ Completed _Thank You!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
